{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "import numpy\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client.client.exceptions import InfluxDBError\n",
    "from getpass import getpass\n",
    "import sys, os\n",
    "import datetime\n",
    "import time as time_module\n",
    "import calendar\n",
    "import json\n",
    "import dateutil, pytz\n",
    "import pandas as pd\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remote (idiotdb)\n",
    "bucket_remote = \"\"\n",
    "org_remote = \"\"\n",
    "token_remote = \"\"\n",
    "# Store the URL of your InfluxDB instance\n",
    "url_remote=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set client to get access to influx\n",
    "clientV2_remote = influxdb_client.InfluxDBClient(\n",
    "   url=url_remote,\n",
    "   token=token_remote,\n",
    "   org=org_remote\n",
    ")\n",
    "### set bucket api\n",
    "buckets_api_remote = clientV2_remote.buckets_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### warning: times out outside Glasgow (use VPN)\n",
    "### list buckets (by name)\n",
    "try:\n",
    "    #print([x.name for x in buckets_api_remote.find_buckets().buckets])\n",
    "    database_list=[x.name for x in clientV2_remote.buckets_api().find_buckets().buckets]\n",
    "    print(database_list)\n",
    "except:\n",
    "    print(\"cannot get buckets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find bucket\n",
    "buckets_api_remote.find_bucket_by_name('GLADD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set query api\n",
    "query_api_remote = clientV2_remote.query_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build query (example for GLADD influx)\n",
    "# set time period\n",
    "start_time_str=\"2023-08-01_23:00:00\"\n",
    "start_time=datetime.datetime.strptime(str(start_time_str), '%Y-%m-%d_%H:%M:%S')\n",
    "start_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "offset_time=60 #s\n",
    "end_time = start_time + datetime.timedelta(seconds=offset_time)\n",
    "end_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "# set filters\n",
    "filters={'_measurement':\"data\"}\n",
    "# build query str\n",
    "query_str = ' from(bucket: \\\"'+bucket_remote+'\\\") |> range(start: '+start_time.strftime('%Y-%m-%dT%H:%M:%SZ')+', stop: '+end_time.strftime('%Y-%m-%dT%H:%M:%SZ')+')'\n",
    "for k,v in filters.items():\n",
    "    query_str+=' |> filter(fn: (r) => r[\"'+k+'\"] == \"'+v+'\")'\n",
    "query_str+=' |> yield(name: \"mean\")'\n",
    "print(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### send query and show result (dataframe version)\n",
    "query_result_remote = query_api_remote.query_data_frame(org=org_remote, query=query_str)\n",
    "display(query_result_remote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get timestamp info for 1st element\n",
    "tmsp=query_result_remote.to_dict()['_time'][0]\n",
    "print(tmsp.to_pydatetime().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get temperature information\n",
    "results = []\n",
    "field=\"temperature\"\n",
    "for index, row in query_result_remote.iterrows():\n",
    "    if row['_field']==field:\n",
    "        results.append(row.to_dict())\n",
    "print(results)"
   ]
  },

{
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    import os
import pandas as pd
from datetime import date
import datetime
import influxdb_client

def fetch_temperature_and_humidity(start_time_str, offset_time, bucket_remote, url_remote, token_remote, org_remote):
    clientV2_remote = influxdb_client.InfluxDBClient(url=url_remote, token=token_remote, org=org_remote)
    query_api_remote = clientV2_remote.query_api()

    start_time = datetime.datetime.strptime(str(start_time_str), '%Y-%m-%d_%H:%M:%S')
    end_time = start_time + datetime.timedelta(seconds=offset_time)

    filters = {'_measurement': "data"}
    query_str = f'from(bucket: \"{bucket_remote}\") |> range(start: {start_time.strftime("%Y-%m-%dT%H:%M:%SZ")}, stop: {end_time.strftime("%Y-%m-%dT%H:%M:%SZ")})'
    for k, v in filters.items():
        query_str += f' |> filter(fn: (r) => r["{k}"] == "{v}")'
    query_str += ' |> yield(name: "mean")'

    query_result_remote = query_api_remote.query_data_frame(org=org_remote, query=query_str)

    temperature_results = []
    humidity_results = []
    for index, row in query_result_remote.iterrows():
        if row['_field'] == 'temperature':
            temperature_results.append(row.to_dict())
        elif row['_field'] == 'humidity':
            humidity_results.append(row.to_dict())

    if len(temperature_results) > 0:
        temperature = temperature_results[0]['_value']
    else:
        temperature = None

    if len(humidity_results) > 0:
        humidity = humidity_results[0]['_value']
    else:
        humidity = None

    return temperature, humidity

def perform_calculations(input_folder, output_file, bucket_remote, url_remote, token_remote, org_remote):
    all_data = []
    
    for filename in os.listdir(input_folder):
        if filename.endswith('.csv'):
            file_path = os.path.join(input_folder, filename)
            data = pd.read_csv(file_path)
            
            # Calculate Vin Drop and GND Drop
            data['Vin Drop (V)'] = data['Vin+ Last (V)'] - data['Vin- Last (V)']
            data['GND Drop (V)'] = data['GND+ Last (V)'] - data['GND- Last (V)']
            
            # Calculate Resistance Vin(Ohms) and Total Resistance(mOhms)
            data['Resistance Vin(Ohms)'] = data['Vin Drop (V)'] / 10 / 5
            data['Resistance GND(Ohms)'] = data['GND Drop (V)'] / 10 / 5
            data['Total Resistance(mOhms)'] = (data['Resistance Vin(Ohms)'] + data['Resistance GND(Ohms)']) * 1000
            
            # Calculate Capacitor Equivalent leakage current(nA)
            data['Capacitor Equivalent leakage current(nA)'] = ((data['Capacitor leakage test Last (V)'] / 10) / (1 * 10 ** 6)) / 1000000
            
            # Calculate NTC value(Kohms)
            data['NTC value (Kohms)'] = 0.2 * 51 / data['NTC Last (V)']
            
            # Fetch temperature and humidity
            start_time_str = "2023-08-01_23:00:00"
            offset_time = 60  # seconds
            temperature, humidity = fetch_temperature_and_humidity(start_time_str, offset_time, bucket_remote, url_remote, token_remote, org_remote)
            
            # Prepare the new DataFrame with desired columns and values
            result_data = pd.DataFrame({
                'component': filename,
                'componentType': 'PCB',
                'stage': 'PCB_QC',
                'testType': 'HV_LV_TEST',
                'institution': 'Glasgow',
                'runNumber': data.shape[0],
                'date': date.today().strftime('%Y-%m-%d'),
                'passed': 'YES',
                'problems': 'False',
                'property1_value': 'B.masic',
                'property1_key': 'OPERATOR',
                'property2_value': 'INSTRUMENT',
                'property2_key': '',
                'property3_value': 'ANALYSIS_VERSION',
                'property3_key': '',
                'result1_key': 'VIN_DROP',
                'result1_value': data['Vin Drop (V)'],
                'result2_key': 'GND_DROP',
                'result2_value': data['GND Drop (V)'],
                'result3_key': 'EFFECTIVE RESISTANCE',
                'result3_value': data['Total Resistance(mOhms)'],
                'result4_key': 'HV_LEAKAGE',
                'result4_value': data['Capacitor leakage test Last (V)'],
                'result5_key': 'LEAKAGE_CURRENT (nA)',
                'result5_value': data['Capacitor Equivalent leakage current(nA)'],
                'result6_key': 'NTC_VOLTAGE',
                'result6_value': data['NTC Last (V)'],
                'result7_key': 'NTC_VALUE',
                'result7_value': data['NTC value (Kohms)'],
                'result8_key': 'TERMPERATURE',
                'result8_value': temperature,
                'result9_key': 'HUMIDITY',
                'result9_value': humidity
            })
            
            all_data.append(result_data)
    
    if all_data:
        final_result = pd.concat(all_data, ignore_index=True)
        final_result.to_csv(output_file, index=False)
        print(f"Calculation completed. Output saved to {output_file}.")

if __name__ == "__main__":
    import os
    cwd = os.getcwd()
    input_folder = cwd+"/../Glasgow Internship/picolog_folder"
    output_file = cwd+"/../Glasgow Internship/output_file.csv"
    bucket_remote = "GLADD"
    org_remote = "PPE"
    token_remote = "EO3dz3f5Bee1T45loRbpyk0SmHAkjOyB0qgKsv2Zc_NPW1_IBwy-odhRgVpPxBftVre63C4eS7V55EhCWbKqHQ=="
    url_remote = "http://194.36.1.20:8086"
    perform_calculations(input_folder, output_file, bucket_remote, url_remote, token_remote, org_remote)

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
